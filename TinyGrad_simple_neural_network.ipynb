{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujirou/Neural-Net-Binary-Classification/blob/main/TinyGrad_simple_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXkPG6Jw4IeV",
        "outputId": "fdf3806c-0587-4583-ca34-e6098d935f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tinygrad'...\n",
            "remote: Enumerating objects: 25539, done.\u001b[K\n",
            "remote: Counting objects: 100% (2573/2573), done.\u001b[K\n",
            "remote: Compressing objects: 100% (297/297), done.\u001b[K\n",
            "remote: Total 25539 (delta 2407), reused 2370 (delta 2272), pack-reused 22966\u001b[K\n",
            "Receiving objects: 100% (25539/25539), 23.66 MiB | 20.69 MiB/s, done.\n",
            "Resolving deltas: 100% (18576/18576), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/geohot/tinygrad.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd tinygrad/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avBrurqQ4hSi",
        "outputId": "6809bcf9-24f0-44b1-9b89-4b4583b261c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tinygrad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B7v05Ax72Z-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw60wfCf4iXJ",
        "outputId": "f2be7b7e-1dc1-4a07-9aa6-97e025bbb449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/tinygrad\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (2.27.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (8.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (4.65.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (3.1)\n",
            "Collecting pyopencl (from tinygrad==0.6.0)\n",
            "  Downloading pyopencl-2023.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (919 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m919.2/919.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (6.0)\n",
            "Collecting pytools>=2021.2.7 (from pyopencl->tinygrad==0.6.0)\n",
            "  Downloading pytools-2023.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pyopencl->tinygrad==0.6.0) (3.7.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tinygrad==0.6.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tinygrad==0.6.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->tinygrad==0.6.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tinygrad==0.6.0) (3.4)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2021.2.7->pyopencl->tinygrad==0.6.0) (4.6.3)\n",
            "Installing collected packages: pytools, pyopencl, tinygrad\n",
            "  Running setup.py develop for tinygrad\n",
            "Successfully installed pyopencl-2023.1.1 pytools-2023.1 tinygrad-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Mcc0x3TP4iTw",
        "outputId": "a27a6ff0-6589-444b-9b6b-f79a1aeb02ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/tinygrad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from tinygrad.tensor import Tensor\n",
        "from tinygrad.nn import optim\n",
        "import tinygrad.nn as nn\n",
        "from tinygrad.helpers import flatten\n",
        "from tinygrad.nn.optim import SGD\n",
        "from sklearn.datasets import fetch_openml"
      ],
      "metadata": {
        "id": "XE4wHwfy4iQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False, )\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prEZ0rh_4iNM",
        "outputId": "b81965c7-0f5f-449d-84c1-cbee5f04a751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784) (70000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tinygrad.nn import Linear\n",
        "\n",
        "class TinyNet:\n",
        "  def __init__(self):\n",
        "    self.l1 = nn.Linear(784, 128, bias=False)\n",
        "    self.l2 = nn.Linear(128, 10, bias=False)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = self.l1(x)\n",
        "    x = x.leakyrelu()\n",
        "    x = self.l2(x)\n",
        "    return x.log_softmax()\n",
        "\n",
        "net = TinyNet()"
      ],
      "metadata": {
        "id": "teQLze0b4iDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tensor.training = True"
      ],
      "metadata": {
        "id": "l7I-HZvs5JF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from extra.training import sparse_categorical_crossentropy\n",
        "def cross_entropy(out, Y):\n",
        "  num_classes = out.shape[-1]\n",
        "  YY = Y.flatten().astype(np.int32)\n",
        "  y = np.zeros((YY.shape[0], num_classes), np.float32)\n",
        "  y[range(y.shape[0]),YY] = -1.0*num_classes\n",
        "  y = y.reshape(list(Y.shape)+[num_classes])\n",
        "  y = Tensor(y)\n",
        "  return out.mul(y).mean()"
      ],
      "metadata": {
        "id": "f6TLHPvx5JCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tinygrad.nn.optim import SGD\n",
        "opt = SGD([net.l1.weight, net.l2.weight], lr=3e-4)"
      ],
      "metadata": {
        "id": "JnIvH9hg5I_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2000\n",
        "\n",
        "weight_bias_dictionary = {}\n",
        "running_loss, correct, total = 0.0, 0.0, 0.0\n",
        "for epoch in range(num_epochs):\n",
        "    weigth_bias = {}\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Randomly sample a batch\n",
        "    samp = np.random.randint(0, X.shape[0], size=(64))\n",
        "    batch = Tensor(X[samp].astype('float32') / 255.0, requires_grad=False)\n",
        "    # Get the corresponding labels\n",
        "    labels = y[samp]\n",
        "\n",
        "    # Forward pass\n",
        "    out = net(batch)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = cross_entropy(out, labels)\n",
        "\n",
        "    # Zero gradients\n",
        "    opt.zero_grad()\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    opt.step()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    pred = np.argmax(out.numpy(), axis=-1)\n",
        "    labels = [eval(label) for label in labels]\n",
        "\n",
        "    acc = (pred == labels).mean()\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"Time Taken: {time.time()-start_time:.3f}s, Epoch [{epoch+1}/{num_epochs}], Loss: {loss.numpy():.5f}, Accuracy: {acc:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PStF7sTd5I7_",
        "outputId": "53c0b1cb-6762-43b2-b9e6-fb39b54ae44d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Taken: 0.025s, Epoch [1/2000], Loss: 2.30219, Accuracy: 0.14062\n",
            "Time Taken: 0.009s, Epoch [101/2000], Loss: 2.31252, Accuracy: 0.18750\n",
            "Time Taken: 0.008s, Epoch [201/2000], Loss: 2.27642, Accuracy: 0.21875\n",
            "Time Taken: 0.009s, Epoch [301/2000], Loss: 2.28463, Accuracy: 0.20312\n",
            "Time Taken: 0.009s, Epoch [401/2000], Loss: 2.26676, Accuracy: 0.21875\n",
            "Time Taken: 0.010s, Epoch [501/2000], Loss: 2.27412, Accuracy: 0.20312\n",
            "Time Taken: 0.009s, Epoch [601/2000], Loss: 2.24246, Accuracy: 0.34375\n",
            "Time Taken: 0.009s, Epoch [701/2000], Loss: 2.24648, Accuracy: 0.26562\n",
            "Time Taken: 0.009s, Epoch [801/2000], Loss: 2.24841, Accuracy: 0.39062\n",
            "Time Taken: 0.009s, Epoch [901/2000], Loss: 2.24378, Accuracy: 0.26562\n",
            "Time Taken: 0.008s, Epoch [1001/2000], Loss: 2.24326, Accuracy: 0.31250\n",
            "Time Taken: 0.008s, Epoch [1101/2000], Loss: 2.24973, Accuracy: 0.23438\n",
            "Time Taken: 0.011s, Epoch [1201/2000], Loss: 2.23119, Accuracy: 0.40625\n",
            "Time Taken: 0.013s, Epoch [1301/2000], Loss: 2.22418, Accuracy: 0.45312\n",
            "Time Taken: 0.009s, Epoch [1401/2000], Loss: 2.22085, Accuracy: 0.45312\n",
            "Time Taken: 0.010s, Epoch [1501/2000], Loss: 2.21320, Accuracy: 0.39062\n",
            "Time Taken: 0.009s, Epoch [1601/2000], Loss: 2.20258, Accuracy: 0.50000\n",
            "Time Taken: 0.010s, Epoch [1701/2000], Loss: 2.18713, Accuracy: 0.48438\n",
            "Time Taken: 0.008s, Epoch [1801/2000], Loss: 2.20631, Accuracy: 0.45312\n",
            "Time Taken: 0.009s, Epoch [1901/2000], Loss: 2.16068, Accuracy: 0.62500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set training flag to false\n",
        "Tensor.training = False\n",
        "\n",
        "st = time.perf_counter()\n",
        "avg_acc = 0\n",
        "for step in range(1000):\n",
        "  # random sample a batch\n",
        "  samp = np.random.randint(0, X.shape[0], size=(64))\n",
        "  batch = Tensor((X[samp].astype('float32') / 255.0), requires_grad=False)\n",
        "  # get the corresponding labels\n",
        "  labels = y[samp]\n",
        "\n",
        "  # forward pass\n",
        "  out = net(batch)\n",
        "\n",
        "  # calculate accuracy\n",
        "  pred = np.argmax(out.numpy(), axis=-1)\n",
        "\n",
        "  labels = [eval(label) for label in labels]\n",
        "  avg_acc += (pred == labels).mean()\n",
        "\n",
        "print(f\"Test Accuracy: {avg_acc / 1000}\")\n",
        "print(f\"Time Taken To Test: {time.perf_counter() - st}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju4f4q5f5tyn",
        "outputId": "47fd1084-be8c-4fc7-e141-905163571fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.49821875\n",
            "Time Taken To Test: 4.262414411000009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t0BUrcXK6V7X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}